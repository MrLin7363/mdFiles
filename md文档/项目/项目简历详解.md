项目简历详解

## 忌讳

华为项目不要说**并发不高**， 高可用网关就说只是前期刚做，所以QPS大概200，但是是稳定的，后期接入了达到2000是没问题的，目前自己的压测能够达到6000  1C2G，如果是4C8G估计能达到10万并发

就说多的时候1千，少的时候50晚上，后期5000至上万是没问题的 ， 一个月可能几亿条数据，分表粒度还可能更大，或者改用es

100 - 6000 - 360000 - 8640000   

jvm 优化， youngGC太频繁，年老代不断增加，适当调大young区，让minGc能更快回收

**是否有C端经验**

说有，不要说只有一点，而且说明C端并没有想象中这么难，更多是分布式锁+一些业务回滚

**不要说什么策略模式也挺简单的**

只是自己觉得简单，是因为自己强，话不要多说



1s单核并发为什么能有5000

因为固定的压测接口，是网关webclient调用一个写好的立刻返回的接口，是正常请求策略

## 华为

### 1. **redis 降级整改**

1.对网关进行 **redis 降级整改**，使用 spring acurator 监控健康逻辑，配合 timer 定时任务+aop+原子类实现 redis 异常快速断连，不影响业务，只要有一个主节点失败就断连

详解： 定时任务每分钟调一次， 如果有两次主节点连续失败，就断连。

​			之前是用AtomicInteger 后面acurator出问题后就不能用这个了

​			一分钟两次定时任务

​			使用两个 copyOnWriteList ，前一次，前前一次， 每个list记录出问题的节点的master IP，每次将前一次的list复制到前前一次的list，如果两个list同时出现相同的master节点，说明某个master节点连续两次出现问题，判断开启降级   ->  修改一个AtimocBoolean的值， aop切redisUtil如果这个值=false则抛出一个异常，redisUtil 所有方法默认都会  tryCatch异常，实现redis不阻塞 

​		如果两个list都为空，说明此时已经恢复，则恢复AtimocBoolean的值

​	

​	slave不是会自动切换上去么？为什么要要整个断？   slave切换上去了又挂了

​	为什么一分钟两次，可以容忍这么多的可用性丢失么？ 1.应对演练够用了  2. redis集群这种情况基本不会发生，本身redis集群就是高可用，时间当然可以设置短一些，这样可以减少性能损耗

### 2. 用户信息熔断器降级模块

人工打开一个定时任务降级

2.对用户登录信息获取系统宕机的高可用演练，设计**熔断器降级模块**，redis 存储用户短期 token 信息，闭路开路实现开启降级后**自动恢复**，判断 IP 等实现安全性

详解： 公司用户中心爆了，能让**最近登陆**过的用户，直接刷新还能访问系统。注意：如果用户换电脑或者清空了前端缓存就不行了

​		还有其他方案，比如手机登录的方式。正常原先登陆逻辑是输入用户名密码到用户中心获取token

​		鉴权网关，所有请求都会通过网关，用户之前登陆成功的时候会把  某个能独立标识用户的XXX-ID(这个ID正常来说是不用的，投机取巧) 发送到网关，网关会 redis存储， 并存储相关的IP信息，   前端也会缓存相关信息

​		熔断器模块是要在运维平台开启定时任务的， 演练开始时，宕机后，开启熔断器模块

​		运维逻辑图  闭路 -> 半开(异步去调用用户系统，判断成功路)

​							半开失败 -> 闭路

​							半开成功  -> 开路



采用时间区间的方式，比如定时任务调用 close()五分钟内不往下做，redis存 xxx_close: 时间戳

如果超过5分钟了，存xxx_half：时间戳   此时会去用计数器判断用户系统是否恢复，如果5分钟调用率没有100%则说明没恢复，会重新回到闭路状态， 此时 删除xxx_half,   更新xxx_close为新的时间戳

如果half恢复率是100% 则新建 open状态，恢复

close()  调用close()闭路，会开启一个redis  switch开关，代码关键位置判断这个开关是否打开，打开会使用redis去获取用户信息，鉴权，使得有前端有缓存的用户能鉴权通过直接跳过登陆访问系统。

​		代码逻辑会调用一次用户系统，如果用户真的失败了,会新建close时间戳，进入闭路状态，这时return true， 运维平台会进入half定时调用逻辑

​		如果当前时间距离闭路时间没大于5分钟，return false;  让运维平台持续调这个接口；

​		如果>5分钟，return true,让平台调第二个接口

half()    新建xxx_half，并异步调用，如果5分钟内几次调用都成功，则return true -> open

​			if 距离xxx_half>5 分钟， 说明半开失败，return flase 重新进入闭路状态 

open()  再次调用用户系统，如果失败则进入闭路状态，否则自循环

这演练其实更多是为了配合，真实情况一般不开启自动开启熔断器的逻辑，因为说是要结合公司的运维平台，实现运维自动化，所以没写相关代码，当出现用户中心问题时，让运维手动人工开启。

### 3. webclient

对比webclient和其他几个http client客户端

好处：对每个事件配置一个线程，只有响应就绪了才会执行

reactive响应式编程

- 非阻塞响应式IO，单位时间内有限资源下支持更高的并发量。
- 支持使用Java8 Lambda表达式函数。
- 支持同步、异步、Stream流式传输。



用到哪些

1. 异常透传.onStatus(HttpStatus::isError, clientResponse -> Mono.empty()) 
2. 响应体大小设置 默认buffer 256 k 容易溢出
3. ssl配置
4. 连接超时和读取超时 ， 由各个系统自己设置
5. provider自定义线程池 最大线程池数，最大队列数，最大等待空闲时间

```
  			ConnectionProvider provider = ConnectionProvider.builder("webClient").maxConnections(500)
                .maxIdleTime(Duration.ofSeconds(20)) // 能够防止connection reset
                .maxLifeTime(Duration.ofSeconds(60))
                .pendingAcquireTimeout(Duration.ofSeconds(60)).evictInBackground(Duration.ofSeconds(120)).build();
```

```
resp.publishOn(Schedulers.elastic())//切换到Schedulers.elastic()对应的线程池进行处理
                .onErrorMap(throwable -> {
                    System.out.println("onErrorMap:" + throwable.getLocalizedMessage());
                    return throwable;
                }).subscribe(s -> System.out.println("result:" + Thread.currentThread().getName() + " " + s));

......block()// 如果是block方式，则不会占用netty的io 默认的CPU个数的selector线程(只负责发请求)，而使用的是服务器tomcat的io线程处理后面逻辑
```





### 4. 策略+责任链模式降级

3.**策略+责任链**模式实现 redis/db 缓存降级，备份地址，熔断等降级**策略**，每次请求到网关，先执行缓存取还是正常请求等

内部调用外部   /Proxy/系统名ALM.../...url



StrategyContext.getStrategy("key").execute();



抽象类  BaseStrategy

```
execute{
 	获取每个handler  责任链执行，如果有一个成功就结束链路执行
 	for(Handler handler: getHandler(vo.getKey())){
 		boolean success=handler.execute(vo);
 		if(success){
 			break;
 		}
 	}	
 	return vo;
}

private abstract get Handler();
```

策略上下文 StrategyContext

```
NormalCacheStrategy  10 
CatheNormalStrategy  01  // cache由配置信息配置是否开启缓存，但是handler都会执行
NormalCachePassStrategy  13
FallbreakStrategy  5

static final Map<String,Strategy> map=new HashMap();

getStrategy(String key){
	return map.getOrDefault(map.get(key), NormalCacheStrategy);
}
```

策略类  xxxStrategy extends BaseStrategy

```
NormalCacheStrategy
CatheNormalStrategy
NormalCachePassStrategy
NormalPassStategy
FallbreakStrategy

@autowaired
private NormalRequestHandler normalRequestHandler;

static final List<Handler> list=new ArrayList();

@PostContruct()
xxx {
	list.add(normalRequestHandler);
	list.add(CacheHandler);
}

xxx getHandler(){
	return list;
}
```

执行各种Handler

NromalRequestHAndler

```
execute()
正常请求http调用   缓存调用等  备份地址  熔断等
```

### 5. 问题

#### 5.1 为什么不用高性能的 kafka用MQ

1.  项目里用了rocketMq
2. rocketMq可靠性更好，可以消息不丢失和不重复投递



## 酷派

### 1. 导出导入离线系统

主要是导出，针对数据量过大,通过生成多个excel文件先写入磁盘 List<File> < 所有对象都在内存，并打成一个zip压缩包上传到云文件桶， 提供下载.   通过mybatis游标查询，每1万条数据合生成一个File 

如果是导入，可以设置一个有界队列，到达数量的时候存入数据库，list.clear() ,  easyexcel有这个功能



模板+策略模式



#### 导入

如果是导入，可以设置一个有界队列，到达数量的时候存入数据库，list.clear() , easyexcel有这个功能

new listener()

```plain
package com.dxh.excel;
 
import com.alibaba.excel.context.AnalysisContext;
import com.alibaba.excel.read.listener.ReadListener;
import com.alibaba.excel.util.ListUtils;
import com.alibaba.fastjson.JSON;
import lombok.extern.slf4j.Slf4j;
 
import java.util.List;
 
// 有个很重要的点 DemoDataListener 不能被spring管理，要每次读取excel都要new,然后里面用到spring可以构造方法传进去
@Slf4j
public class DemoDataListener implements ReadListener<ExcelDemo> {
 
    /**
     * 每隔5条存储数据库，实际使用中可以100条，然后清理list ，方便内存回收
     */
    private static final int BATCH_COUNT = 100;
    /**
     * 缓存的数据
     */
    private List<ExcelDemo> cachedDataList = ListUtils.newArrayListWithExpectedSize(BATCH_COUNT);
    /**
     * 假设这个是一个DAO，当然有业务逻辑这个也可以是一个service。当然如果不用存储这个对象没用。
     */
    private DemoDAO demoDAO;
 
    public DemoDataListener() {
        // 这里是demo，所以随便new一个。实际使用如果到了spring,请使用下面的有参构造函数
        demoDAO = new DemoDAO();
    }
 
    /**
     * 如果使用了spring,请使用这个构造方法。每次创建Listener的时候需要把spring管理的类传进来
     *
     * @param demoDAO
     */
    public DemoDataListener(DemoDAO demoDAO) {
        this.demoDAO = demoDAO;
    }
 
    /**
     * 这个每一条数据解析都会来调用
     *
     * @param data    one row value. Is is same as {@link AnalysisContext#readRowHolder()}
     * @param context
     */
    @Override
    public void invoke(ExcelDemo data, AnalysisContext context) {
        System.out.println (JSON.toJSONString(data));
        cachedDataList.add(data);
        // 达到BATCH_COUNT了，需要去存储一次数据库，防止数据几万条数据在内存，容易OOM
        if (cachedDataList.size() >= BATCH_COUNT) {
            System.out.println ("100条保存");
            saveData();
            // 存储完成清理 list
            cachedDataList = ListUtils.newArrayListWithExpectedSize(BATCH_COUNT);
        }
    }
 
    /**
     * 所有数据解析完成了 都会来调用
     *
     * @param context 120---》100    20====》
     */
    @Override
    public void doAfterAllAnalysed(AnalysisContext context) {
        // 这里也要保存数据，确保最后遗留的数据也存储到数据库
        System.out.println ("after-----------");
 
        saveData();
        log.info("所有数据解析完成！");
    }
 
    /**
     * 加上存储数据库
     */
    private void saveData() {
        log.info("{}条数据，开始存储数据库！", cachedDataList.size());
        demoDAO.save(cachedDataList);
        log.info("存储数据库成功！");
    }
}
```

#### 导出

主要是导出，原先数据库查出全部数据，针对数据量过大的问题

  通过生成多个excel文件先写入磁盘 List<File> < 所有对象都在内存，并打成一个zip压缩包上传到云文件桶，提供下载，上传完后删除磁盘file ，上传过程是转成inputStream

通过mybatis游标查询，每1万条数据合生成一个File 





##### file对象占内存是整个文件大小么

**在Java中，‌创建新文件实际上并不会占用太多的内存空间，‌而创建新文件占用的内存空间主要取决于文件本身的大小，‌而不是File对象本身。‌** 当我们使用`new File()`方法来创建一个新的File对象时，‌这个操作只是在内存中分配了一个File对象，‌而这个对象本身占用的内存非常小。‌实际上，‌文件的内容并没有在内存中存储，‌而是存储在磁盘上。‌因此，‌创建File对象并不会直接导致大量的内存占用，‌除非当文件内容被读入内存进行操作时，‌才会占用更多的内存空间。‌





##### java ZipInputStream 会比整个zip文件大么

`ZipInputStream`用于读取ZIP文件的内容，‌它本身并不存储数据，‌而是从ZIP文件中读取数据并将其提供给应用程序。‌因此，‌`ZipInputStream`的大小不会比整个ZIP文件大，‌因为它只是ZIP文件内容的流式传输方式。‌使用`ZipInputStream`读取ZIP文件时，‌数据是从ZIP文件中逐个字节读取的，‌而不是将整个ZIP文件的内容一次性加载到内存中。‌这意味着，‌从理论上讲，‌`ZipInputStream`的大小始终与ZIP文件的大小保持一致，‌或者更准确地说是与当前正在读取的部分保持一致。‌因此，‌通过`ZipInputStream`读取的数据量不会超过ZIP文件本身的大小



##### java 上传文件到服务器是先把文件全部加载到内存么

在Java中，上传文件到服务器通常使用HTTP协议，这是通过网络进行的。文件不需要完全加载到内存中，而是以流的形式进行传输。这意味着文件可以分块传输，每次只读取一块数据发送到服务器。

### 3. 加解密订单敏感字段

通过 mybatis  的拦截器拦截  参数和结果返回，  配合注解，实现加解密、

### 3. 拆单合单

状态流转机器

履约中心：原始交易单（MQ存） ， 订单， 发货单，  快递单， 快递包裹



#### 3.1 相关订单状态

```
交易单被拆单完就是完成状态，后面发货就是订单和发货单相关的事情
public enum TradeStatusEnum implements IEnum<Integer> {

    INIT_TRADE(1, "初始交易单"), //

    WAITING_AUDIT(100, "待审核"),

    WAITING_SPLIT(200, "待拆单"),

    WAITING_SHIPPING(300, "等待发货"), // 拆交易单

    SHIPPING(500, "发货中"),

    WAITING_FOR_RECEIVE(600, "等待收货"), // 发货回调

    COMPLETE(1000, "已完成"), // 用户点确认

    CLOSE(-1000, "已关闭"),

    ;
```



```
   订单状态
  
  INIT_ORDER(1, "初始订单"),
    /**
     * 待审核
     */
    WAIT_AUDIT(100, "待审核"),
    /**
     * 已拆单完成，子订单 已拆分
     */
    ORDER_SPLITED(200, "已拆单"),
    /**
     * 已合并发货单  订单合并为发货单
     */
    SHIPMENT_MERGED(260, "发货单已合并"),
    /**
     * 仓库已接单
     */
    WMS_ACCEPTED(300, "仓库已接单"),
    /**
     * 已筛单，分配快递单号
     */
    EXPRESS_ASSIGNED(500, "已筛单"),
    /**
     * 仓库已发货,快递已发出
     */
    WMS_SHIPPED(600, "快递已发出"),
    /**
     * 快递员确认已送达
     */
    EXPRESS_DELIVERED(800, "快递已送达"),
    /**
     * 收货人确认已签收 / 订单已完成
     */
    CONSIGNEE_SIGNED(1000, "已完成"),
    /**
     * 异常订单
     */
    EXCEPTION(-100, "异常订单-发网缺货-拦截"),
    /**
     * 订单已取消
     */
    CANCELED(-1000, "已取消"),
    ;
```

```
 发货单 状态
     INIT(1, "初始发货单"),
    SHIPMENT_WAIT(100, "等待筛单"),
    WAIT_ASSIGNED(400, "等待发货"), // OrderStatusEnum  500
    WMS_SHIPPED(800, "已发货"), // OrderStatusEnum  600
    EXPRESS_DELIVERED(1000, "已完成"),
    CANCELED(-1000, "已取消"),
    ;
```



#### 3.3 拆实物订单

每个流程都是定时任务

单个 交易单->  单个父订单

```
SplitTradeToOrderTask.splitTradeToOrderTask ->SplitTradeAction
先把交易单所有商品列表展开 
交易单状态-> 等待发货
订单状态  ->  初始订单
```

单个父订单 -> 单个子订单(选了仓库，扣减了库存)

```
StandardShipmentOrderTask. splitOrderTask -> SplitOrderAction

先择仓库，选计算每个sku在 单个仓库都满足的仓库
扣减真实库存，加上分布式锁， 调库存中心http接口，如果后面代码逻辑有失败，则回滚库存

子订单状态  ->  已拆单
父订单状态 parent_id=1  -> 取消
```



子订单  -> 合并订单至发货单

```
StandardShipmentOrderTask.mergeOrderTask  ->mergeOrderTask
按照订单group分组后，每个组一个发货单
发货单状态  -> 初始发货单
子订单状态  >  已拆单

     * 订单分组
     * 同一个用户 相同发货仓 相同销售渠道 相同收货人姓名、手机号、详细地址 合并发货
    public String groupingByOrderMerge() {
        return getWmsCode() + getOuterRdcCode() + getDcCode() + getUserId() + getChannelCode()
                + consignee.getName() + consignee.getTel() + consignee.getAddress();// fixme
    }
    
    // 如果出错了，直接用这个不合单
    public String groupingByOrderId() {
        return getOrderId().toString();// fixme 使用ID  不合并订单
    }

```



发货单 扫1万条 -> 发货

```
StandardShipmentOrderTask.shippingOrderTask  -> ShippingOrderAction
发网或者 恒达  创建发货单

子订单状态  >  仓库已接单
发货单状态  > 等待筛单
```



发网订单确认回调接口

```
订单（已筛单） +  发货单状态（等待发货）
```



定时任务查询订单状态

```
FineexShipmentProcessGetTask

订单 -> 快递已发出
发货单  -> 已发货
```

#### 3.3 发网发快递

发快递方式： 恒达  + 发网

发网发货回调履约中心， 修改订单（已筛单） +  发货单状态（等待发货）

发网收货回调

发网退货回调 ， 履约中心修改相关状态 + 回滚库存   调库存中心接口



```
发网相关接口

创建发货单
取消发货单
订单流转数据查询接口
退货单创建接口
退货单取消接口
快递物流详情查询接口
```



#### 3.5 状态机

除了定时任务各个阶段去扫描，当一个流程流转完，返回的订单ID可以直接执行下一个流程，所以是一个链路同时执行的

```
/**
 * 待拆单
 */
WAITING_SPLIT(StandardOrderShippingEventEnum.SPILT_ORDER),
/**
 * 待合并
 */
WAITING_MERGE(StandardOrderShippingEventEnum.MERGE_ORDER),
/**
 * 待发货
 */
WAITING_SHIPPING(StandardOrderShippingEventEnum.SHIPPING_ORDER),
;
```

#### 3.4 拆虚拟订单

```
SyncTradeMqListener 监听交易单并且入库 
-> SplitTradeToOrderTask  定时任务，交易单取1万条进行拆单
-> SplitVirTradeAction   虚拟单拆单逻辑  ，拆弹不成功状态不变，下一次还会继续被扫描出来拆单

```



```
/**
 * 订单分组
 * 同一个用户 相同发货仓 相同销售渠道 相同收货人姓名、手机号、详细地址 合并发货
 *
 * @return
 */
```

#### 3.5 话费充值

提供 adk , 这边只需要填入appSecret 即可

充值后回调，这边修改状态，不是很难



虚拟订单拆分后  会根策略模式  根据 该单的交易类型 判断走哪个虚拟商品履约

具体确认了什么虚拟交易后，  会策略模式选择对应供应商，比如花费充值有多个供应商可以提供充值接口， 从redis中拿到key去找对应供应商充值话费



拆单如果失败会通知交易中心

```
    PHONE_RECHARGE(1, "花费充值", "phoneRechargeHandler", "fulfillment:phone:recharge:type", "recharge"),
    FLOW_RECHARGE(2, "流量充值", "flowRechargeHandler", "fulfillment:flow:recharge:type", "recharge"),
    VIDEO_AIQIYI(3, "爱奇艺黄金会员", "videoAQYHandler", "fulfillment:video:aiqiyi:type", "recharge"),
    VIDEO_TENGXUN(4, "腾讯视频VIP", "videoTCHandler", "fulfillment:video:tengxun:type", "recharge"),
    VIDEO_YOUKU(5, "优酷黄金会员", "videoYKHandler", "fulfillment:video:youku:type", "recharge"),
    ENVELOPE_MEITUAN(6, "美团外卖红包", "envelopMTHandler", "fulfillment:envelope:meituan:type", "recharge"),
    CARD_KENGDEJI(7, "肯德基礼品卡", "cardKDJHandler", "fulfillment:card:kengdeji:type", "card"),
    CARD_JINGDONG(8, "京东E卡", "cardJDHandler", "fulfillment:card:jingdong:type", "card"),
```

```
orderHandlerMap.get(OrderChildTypeEnum.getHandler(existOrder.getOrderChildType())).execute(existOrder);

supplyHandlerMap.get(SupplyEnum.getHandler(getSupplyKey(OrderChildTypeEnum.PHONE_RECHARGE.getRedisKey())))
       .execute(order, OrderChildTypeEnum.PHONE_RECHARGE);
```



### 4. 支付和退款

表：支付流水记录  退款流水记录   支付配置表   支付退款不成功回调表

支付逻辑

两个接口 

pay   交易中心调支付，进行预支付

getByid   获取预支付的前端渲染信息

payNotify 微信回调

```
支付流程：交易中心下单时请求网关向微信发送预支付  并且把回调地址告诉微信，如果成功，返回支付单ID给前端
	前端下单成功后，支付的时候通过支付凭证ID向支付中心请求 支付渲染的数据
	
客户支付完后，微信会调支付网关得notify接口；  返回json字符串，支付网关根据渠道解析； 如果支付记录状态(PENDING,FAIL,SUCCESS)==PENDING 幂等
则 回调交易中心返回支付成功，如果catch失败插入回调表，  不管怎样都返回微信成功的标识

回调表定时任务扫描失败的记录进行回调, 进行次数 + 每次延迟的情况

如果通知失败则采用回调表定时任务检查的方式;
```

**退款逻辑**

```
交易中心 -> 支付网关refund 接口  支付单号，退款单号-交易中心生成，退款金额，回调交易中心URL

refund接口 -> 校验所有的退款成功的单号，如果总退款金额>当前支付单号金额，则不给退款  
       -> 调微信预退款， 成功返回状态设置 PENDING状态，等待微信成功退款后回调
       
 
refundNotify 接口-> 微信退款回调， 此时也要回调交易中心，如果失败就加入流水记录表回调
```

**金额校验逻辑**

下面原先的代码是有问题的，如果同时多个退款请求，可能会造成退多的情况,， 但是因为交易中心用户取消交易单的逻辑已经加了分布式锁，所以同时只会有一个请求进来退款，没有问题

因为没有涉及扣减，只是涉及数据库条数，所以没有用mysql相关的锁

```
   private RefundOrder checkAndBuildRefund(RefundPaymentCmd cmd,Payment payment){
        // 查询所有退款成功单，检验可退款金额
        // PayStatus.SUCCEED.getValue() + , PayStatus.PENDing.getValue()  如果有一个在退款中，这里也不能让之预退款
        // 查到的同时需要锁定，这里需要加分布式锁，不可以让同一个支付流水同时多个退款申请同时进行
        List<RefundOrder> refundList=refundOrderRepository.queryListByPaymentId(payment.getId(), PayStatus.SUCCEED.getValue());
        Long refundSum=0L;
        for (RefundOrder order:refundList){
            refundSum+=order.getRefundAmount();
        }
        refundSum+=cmd.getRefundAmount();
        if (refundSum.compareTo(payment.getAmount())>0){
            throw new BizException(ExceptionCode.REFUND_AMOUNT_IS_WRONG.getCode(),ExceptionCode.REFUND_AMOUNT_IS_WRONG.getDesc());
        }
```

或者悲观锁 for update  将查询所有记录和校验的逻辑放到一个@Transactional 里

```
 /**
     * 添加事务
     * @param productId
     * @return
     */
    @Transactional // 让下面的查询和修改在同一个事务里
    @Override
    public String deductStock(Integer productId) {
       Stock stock = stockMapper.selecStockForUpdate(productId);
       if(stock != null && stock.getStockNum() > 0 ){
           stock.setStockNum(stock.getStockNum() -1);
           int updateCount = stockMapper.updateById(stock);
           if (updateCount > 0 ){
               return "扣减库存成功";
           }else{
               return "扣减失败";
           }
       }
       return "库存库存失败:商品库存不存在或者库存为0";
    }
    
    
       @Select("SELECT * FROM test.stock where product_id = #{productId} for update")
    Stock selecStockForUpdate(Integer productId);


```

### 5. 转单中心

目前只有**拉取订单**和**发货回调快手**    还有一个**接口提供下游系统调用拉取转单下单** ,  还有**手动excel导入转单中心**，    后面加上了退款功能（不是我做的）



**拉取订单**  KuaishouOrderPullTaskExe   kwaiGetOrderListTask() 

定时任务拉取快手订单，拉取近7天的订单，并且记录定时任务每次拉取的成功或失败，记录最新的游标，每次查询100条

拉取的订单是快手返回的VO是已经支付状态的，其他的不行

存入转单中心交易数据库



**excel转单 upload接口 **    PlatformTradeController.upload接口

用于一些补发等情况，由业务找我给excel给我补发，前期功能不全，发漏等情况

将excel的订单导入转单中心的数据库，等待下游调用转单，或者没下单交易单，需要修改订单信息，临时修改oreder_json



**发货回调快手**   KuaishouShipmentInvoker

将快递单号，快递公司类型，快手的订单号发给快手 



**接口提供下游系统调用拉取转单下单**   @GetMapping(value = "/place")  kuaishouOrderPullTaskExe. placeOrdertTaskShoudong

交易中心调这边，这边拉取近10000条交易发送给交易中心下单接口



**调快手api**

调快手， 有client api包提供了调用方法， 主要有accessKey , refreshKey 两个都会过时

accessKey 用于访问快手相关拉取订单接口

refreshKey  获取最新的accessKey 和 refreshKey

```
KsAccessTokenResponse ksAccessTokenResponse = oauthAccessTokenKsClient.refreshAccessToken(refreshToken);
```

通过本地存的code  刷新refreshKey，当这个也过期的时候

```
oauthAccessTokenKsClient.getAccessToken(code);
```

需要不定时refreshKey 



```
create table `third_trade`
(
    id                  bigint(20) not null auto_increment,
    from_channel        smallint(6) not null comment '渠道来源编码',
    from_channel_name   VARCHAR(100) not null comment '渠道来源名称',
    translate_id        bigint(20) not null comment '转单号',  //  雪花算法自己生成的
    trade_id            bigint(20) comment '交易单号',
    third_order_id      VARCHAR(100) not null comment '第三方订单号',
    shop_id             VARCHAR(64) comment '门店ID',
    order_json          longtext not null comment '订单json', // 存各平台的订单全部信息，如excel 或者快手，  转对应的vo就行
    translate_status    smallint(6) not null comment '转单状态 eg.待转单:1 已转单成功:2',
    third_order_status  VARCHAR(20) comment '第三方订单状态',
    refund_status       smallint(6) default 0 comment '退款状态 eg.未退款:0 已申请退款:1',
    order_time          bigint(20) not null comment '下单时间',
    create_time         bigint(20) not null comment '创建时间',
    update_time         bigint(20) not null comment '更新时间',
    unique index `trade_idx` (`trade_id`),
    primary key (`id`)
) COMMENT = '原始交易表';

create table `third_trade_call_log`
(
    id                  bigint(20) not null auto_increment,
    service_name        varchar(100) not null comment '请求服务名称',
    request_data        text comment '请求json',
    status              smallint(6) not null comment '查询状态 eg.成功:1 失败:2',
    error_msg           text comment '错误信息',
    pcursor             varchar(100) not null comment '游标',
    time_consuming      bigint(20) not null comment '响应时长',
    create_time         bigint(20) not null comment '创建时间',
    primary key (`id`)
) COMMENT = '原始交易表';

```

定时任务拉取快手订单，   KuaishouOrderPullTaskExe

```
   private OpenSellerOrderPcursorListRequest buildRequest() {
        // https://open.kwaixiaodian.com/docs/api?apiName=open.seller.order.pcursor.list&categoryId=43&version=1
        OpenSellerOrderPcursorListRequest request = new OpenSellerOrderPcursorListRequest();
        request.setType(3);
        request.setCurrentPage(1L);
        request.setPageSize(100);
        request.setSort(2);
        request.setQueryType(1);
        request.setEndTime(System.currentTimeMillis());
        request.setBeginTime(System.currentTimeMillis() - 167 * 60 * 60 * 1000 - 60 * 1000);
        request.setCpsType(0);
        request.setPcursor(getPcursor(TradeFromChannelEnum.KUAISHOU.getName()));
        return request;
    }
```





### 7. 泛微OA中转模块

提供中转，运用了枚举 去反射调用网关方法

```
 @ApiOperation(value = "拉取待审核订单")
    @GetMapping("/process/get")
    public MultiResponse<WorkflowCO> get(@RequestParam("workflowId")String workflowId){
        return workflowService.getProcess(workflowId);
    }

    @ApiOperation(value = "泛微回调接口")
    @PostMapping("/process/notify")
    public SingleResponse notify(@RequestBody @Validated WorkflowNotifyCmd workflowNotifyCmd){
        return workflowService.notifyWorkflow(workflowNotifyCmd);
    }
```

```
 TRADE("53", "com.coolpad.basic.infrastructure.workflow.gateway.FulfillmentFeign","getWorkflow","notifyWorkflow");

    private String workflowId;

    private String feign;

    private String pullMethod;

    private String notifyMethod;


    WorkflowEnum(String workflowId, String feign, String pullMethod, String notifyMethod) {
        this.workflowId = workflowId;
        this.feign = feign;
        this.pullMethod = pullMethod;
        this.notifyMethod = notifyMethod;
    }

    public static WorkflowEnum getWorkflowEnum(String workflowId) {
        for (WorkflowEnum workflowEnum : WorkflowEnum.values()) {
            if (workflowEnum.workflowId.equals(workflowId)) {
                return workflowEnum;
            }
        }
        throw new BizException("WorkflowUrlEnum does not have this workflowId",workflowId);
    }

```

```
    ReflectionUtils.findMethod(feign.getClass(), workflowEnum.getNotifyMethod(), WorkflowNotifyGO.class);
```

### 8. 库存中心简介 

下单扣减销售库存逻辑

```
   @Transactional(rollbackFor = Exception.class)
    public SingleResponse execute(ReduceStockCmd reduceStockCmd) {
        log.info("reduceSalesStockCmd---{}", reduceStockCmd);
        ReduceStockCO reduceStockCO = convert(reduceStockCmd);
        boolean flag = false;
        //查询对应的销售库存列表
        for (ReduceStockCO.SkuInfo skuInfo : reduceStockCO.getSkuList()) {
            flag = false;
            String reduceSalesKeyBySku = lockKey + skuInfo.getSku();
            if (redissLockUtils.tryLock(reduceSalesKeyBySku, waitTime)) {
                try {
                    List<SalesStock> salesStocks = salesStockRepository.findDcCode(reduceStockCO.getChannelCode(), skuInfo.getSku());
                    for (SalesStock salesStock : salesStocks) {
                        //扣减第一个满足的销售库存
                        StockAreaBo stockAreaBo = BeanConvertUtils.convertTo(reduceStockCO, StockAreaBo.class);
                        if (checkIsInArea(stockAreaBo, salesStock) && checkAndReduce(salesStock, reduceStockCO.getTradeNo(), skuInfo.getAmount())) {
                            flag = true;
                            break;
                        }
                    }
                } catch (Exception e) {
                    log.error("reduceSalesStock-error", e);
                    flag = false;
                } finally {
                    redissLockUtils.unlock(reduceSalesKeyBySku);
                }
            } else {
                return SingleResponse.buildFailure(ErrorEnum.STOCK_OPERATE_HOT.getCode(), "商品太火爆,请稍后重试");
            }
            if (!flag) {
                return SingleResponse.buildFailure(ErrorEnum.STOCK_NOT_ENOUGH.getCode(), ErrorEnum.STOCK_NOT_ENOUGH.getMsg());
            }
        }
        if (flag) {
            log.info("reduceSalesStock success");
            return SingleResponse.buildSuccess();
        }
        return SingleResponse.buildFailure(ErrorEnum.STOCK_NOT_ENOUGH.getCode(), ErrorEnum.STOCK_NOT_ENOUGH.getMsg());
    }
```

扣减SQL

and amount>=#{amount}

这有点类似乐观锁，但是这里不关心连续修改，只要能修改就行，不用version=version+1

```
@Update("update sales_stock set amount = amount-#{amount} where dc_code=#{dcCode} and channel_code=#{channelCode} and sku = #{sku} and amount>=#{amount}")
```



```
CREATE TABLE `sales_stock`
(
  `id` bigint(0) NOT NULL AUTO_INCREMENT COMMENT '主键ID',
  `channel_code` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '库存渠道编码',
  `dc_code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT 'VDC编码',
  `sku` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT 'sku',
  `amount` int(0) NOT NULL COMMENT '库存数量',
  `create_time` datetime(0) NOT NULL COMMENT '创建时间',
  `update_time` datetime(0) DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  PRIMARY KEY (`id`) USING BTREE
);

CREATE TABLE `real_stock`
(
    `id`             bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键ID',
    `dc_code`        varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '仓库ID',
    `sku`            varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT 'sku编码',
    `remain_amount`  int(10) NULL DEFAULT 0 COMMENT '可售库存',
    `lp_amount`      int(10) NULL DEFAULT 0 COMMENT '良品库存',
    `cp_amount`      int(10) NULL DEFAULT 0 COMMENT '次品库存',
    `transit_amount` int(10) NULL DEFAULT 0 COMMENT '在途库存',
    `sync_time`      datetime NULL DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '数据同步时间',
    `create_time`    datetime NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    PRIMARY KEY (`id`) USING BTREE,
    INDEX            `k_dc_code`(`dc_code`) USING BTREE,
    INDEX            `k_sku`(`sku`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 0 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '库存表 --- 真实仓库库存' ROW_FORMAT = Dynamic;
```

### 9. 交易中心简介

```
AbstractPlaceTemplate

        // 下单锁  平台+销售渠道+上游订单号+用户ID
        String lockKey = RedisKeys.PLACE_TRADE_KEY + trade.getFromPlatform() + ":"
                + trade.getSalesChannelEnum() + ":" + trade.getUpstreamTradeId() + ":" + trade.getUserId();
        if (!redissLockUtils.tryLock(lockKey, 0)) {
            throw new BizException(ResponseError.PLACE_TRADE_ERROR.getCode(), "重复下单异常");
        }

        try {
            // 填充商品信息
            this.fillGoodsInfo(trade);

            // 限购
            this.restrictBuy(trade);

            // 金额计算
            this.calculateAmount(trade, cmd.getCouponCodes());

            // 金额校验
            this.checkSubmitAmount(cmd, trade);

            try {
                // 资源扣减（库存、活动、优惠券等）
                this.deductResource(trade);

                // 现金和积分支付
                this.payment(trade);

                // 创建交易单
                this.createTrade(trade);

                // 发送消息
                this.sendMsg(trade);

                return this.buildResult(cmd, trade);
            } catch (Exception e) {
                log.error("placeTradeError. trade={}, cmd={}", JsonUtils.objToJson(trade), JsonUtils.objToJson(cmd), e);
                try {
                    // 回滚所有资源
                    this.rollbackAllResource(trade);
                } catch (Exception ex) {
                    log.error("placeTradeError rollbackAllResource error. tradeId={}", trade.getTradeId(), ex);
                }
                if (e instanceof BizException) {
                    throw e;
                }
                throw new BizException(ResponseError.PLACE_TRADE_ERROR.getCode(), "网络异常，请稍后重试");
            }
        } finally {
            redissLockUtils.unlock(lockKey);
        }

```
