项目简历详解



## 华为

### 1. **redis 降级整改**

1.对网关进行 **redis 降级整改**，使用 spring acurator 监控健康逻辑，配合 timer 定时任务+aop+原子类实现 redis 异常快速断连，不影响业务，只要有一个主节点失败就断连

详解： 定时任务每分钟调一次， 如果有两次主节点连续失败，就断连。

​			之前是用AtomicInteger 后面acurator出问题后就不能用这个了

​			使用两个 copyOnWriteList ，前一次，前前一次， 每个list记录出问题的节点的master IP，每次将前一次的list复制到前前一次的list，如果两个list同时出现相同的master节点，说明某个master节点连续两次出现问题，判断开启降级   ->  修改一个AtimocBoolean的值， aop切redisUtil如果这个值=false则抛出一个异常，redisUtil 所有方法默认都会  tryCatch异常，实现redis不阻塞 

​		如果两个list都为空，说明此时已经恢复，则恢复AtimocBoolean的值

​	

​	slave不是会自动切换上去么？为什么要要整个断？   系统比较重要，保证完全可用性；BUG分区了，salve没有主背切换

### 2. 用户信息熔断器降级模块

2.对用户登录信息获取系统宕机的高可用演练，设计**熔断器降级模块**，redis 存储用户短期 token 信息，闭路开路实现开启降级后**自动恢复**，判断 IP 等实现安全性

详解： 公司用户中心爆了，能让**最近登陆**过的用户，直接刷新还能访问系统。注意：如果用户换电脑或者清空了前端缓存就不行了

​		还有其他方案，比如手机登录的方式。正常原先登陆逻辑是输入用户名密码到用户中心获取token

​		鉴权网关，所有请求都会通过网关，用户之前登陆成功的时候会把  某个能独立标识用户的XXX-ID(这个ID正常来说是不用的，投机取巧) 发送到网关，网关会 redis存储， 并存储相关的IP信息，   前端也会缓存相关信息

​		熔断器模块是要在运维平台开启定时任务的， 演练开始时，宕机后，开启熔断器模块

​		运维逻辑图  闭路 -> 半开(异步去调用用户系统，判断成功路)

​							半开失败 -> 闭路

​							半开成功  -> 开路



采用时间区间的方式，比如定时任务调用 close()五分钟内不往下做，redis存 xxx_close: 时间戳

如果超过5分钟了，存xxx_half：时间戳   此时会去用计数器判断用户系统是否恢复，如果5分钟调用率没有100%则说明没恢复，会重新回到闭路状态， 此时 删除xxx_half,   更新xxx_close为新的时间戳

如果half恢复率是100% 则新建 open状态，恢复

close()  调用close()闭路，会开启一个redis  switch开关，代码关键位置判断这个开关是否打开，打开会使用redis去获取用户信息，鉴权，使得有前端有缓存的用户能鉴权通过直接跳过登陆访问系统。

​		代码逻辑会调用一次用户系统，如果用户真的失败了,会新建close时间戳，进入闭路状态，这时return true， 运维平台会进入half定时调用逻辑

​		如果当前时间距离闭路时间没大于5分钟，return false;  让运维平台持续调这个接口；

​		如果>5分钟，return true,让平台调第二个接口

half()    新建xxx_half，并异步调用，如果5分钟内几次调用都成功，则return true -> open

​			if 距离xxx_half>5 分钟， 说明半开失败，return flase 重新进入闭路状态 

open()  再次调用用户系统，如果失败则进入闭路状态，否则自循环

这演练其实更多是为了配合，真实情况一般不开启自动开启熔断器的逻辑，因为说是要结合公司的运维平台，实现运维自动化，所以没写相关代码，当出现用户中心问题时，让运维手动人工开启。

### 3. webclient



### 4. 策略+责任链模式降级

3.**策略+责任链**模式实现 redis/db 缓存降级，备份地址，熔断等降级**策略**，每次请求到网关，先执行缓存取还是正常请求等

内部调用外部   /Proxy/系统名ALM.../...url





## 酷派

### 1. 导出导入离线系统

主要是导出，针对数据量过大,通过生成多个excel文件先写入磁盘 List<File> < 所有对象都在内存，并打成一个zip压缩包上传到云文件桶， 提供下载.   通过mybatis游标查询，每1万条数据合生成一个File 

如果是导入，可以设置一个有界队列，到达数量的时候存入数据库，list.clear() ,  easyexcel有这个功能



#### 导入

如果是导入，可以设置一个有界队列，到达数量的时候存入数据库，list.clear() , easyexcel有这个功能

new listener()

```plain
package com.dxh.excel;
 
import com.alibaba.excel.context.AnalysisContext;
import com.alibaba.excel.read.listener.ReadListener;
import com.alibaba.excel.util.ListUtils;
import com.alibaba.fastjson.JSON;
import lombok.extern.slf4j.Slf4j;
 
import java.util.List;
 
// 有个很重要的点 DemoDataListener 不能被spring管理，要每次读取excel都要new,然后里面用到spring可以构造方法传进去
@Slf4j
public class DemoDataListener implements ReadListener<ExcelDemo> {
 
    /**
     * 每隔5条存储数据库，实际使用中可以100条，然后清理list ，方便内存回收
     */
    private static final int BATCH_COUNT = 100;
    /**
     * 缓存的数据
     */
    private List<ExcelDemo> cachedDataList = ListUtils.newArrayListWithExpectedSize(BATCH_COUNT);
    /**
     * 假设这个是一个DAO，当然有业务逻辑这个也可以是一个service。当然如果不用存储这个对象没用。
     */
    private DemoDAO demoDAO;
 
    public DemoDataListener() {
        // 这里是demo，所以随便new一个。实际使用如果到了spring,请使用下面的有参构造函数
        demoDAO = new DemoDAO();
    }
 
    /**
     * 如果使用了spring,请使用这个构造方法。每次创建Listener的时候需要把spring管理的类传进来
     *
     * @param demoDAO
     */
    public DemoDataListener(DemoDAO demoDAO) {
        this.demoDAO = demoDAO;
    }
 
    /**
     * 这个每一条数据解析都会来调用
     *
     * @param data    one row value. Is is same as {@link AnalysisContext#readRowHolder()}
     * @param context
     */
    @Override
    public void invoke(ExcelDemo data, AnalysisContext context) {
        System.out.println (JSON.toJSONString(data));
        cachedDataList.add(data);
        // 达到BATCH_COUNT了，需要去存储一次数据库，防止数据几万条数据在内存，容易OOM
        if (cachedDataList.size() >= BATCH_COUNT) {
            System.out.println ("100条保存");
            saveData();
            // 存储完成清理 list
            cachedDataList = ListUtils.newArrayListWithExpectedSize(BATCH_COUNT);
        }
    }
 
    /**
     * 所有数据解析完成了 都会来调用
     *
     * @param context 120---》100    20====》
     */
    @Override
    public void doAfterAllAnalysed(AnalysisContext context) {
        // 这里也要保存数据，确保最后遗留的数据也存储到数据库
        System.out.println ("after-----------");
 
        saveData();
        log.info("所有数据解析完成！");
    }
 
    /**
     * 加上存储数据库
     */
    private void saveData() {
        log.info("{}条数据，开始存储数据库！", cachedDataList.size());
        demoDAO.save(cachedDataList);
        log.info("存储数据库成功！");
    }
}
```

#### 导出

主要是导出，原先数据库查出全部数据，针对数据量过大的问题

  通过生成多个excel文件先写入磁盘 List<File> < 所有对象都在内存，并打成一个zip压缩包上传到云文件桶，提供下载，上传完后删除磁盘file ，上传过程是转成inputStream

通过mybatis游标查询，每1万条数据合生成一个File 





##### file对象占内存是整个文件大小么

**在Java中，‌创建新文件实际上并不会占用太多的内存空间，‌而创建新文件占用的内存空间主要取决于文件本身的大小，‌而不是File对象本身。‌** 当我们使用`new File()`方法来创建一个新的File对象时，‌这个操作只是在内存中分配了一个File对象，‌而这个对象本身占用的内存非常小。‌实际上，‌文件的内容并没有在内存中存储，‌而是存储在磁盘上。‌因此，‌创建File对象并不会直接导致大量的内存占用，‌除非当文件内容被读入内存进行操作时，‌才会占用更多的内存空间。‌





##### java ZipInputStream 会比整个zip文件大么

`ZipInputStream`用于读取ZIP文件的内容，‌它本身并不存储数据，‌而是从ZIP文件中读取数据并将其提供给应用程序。‌因此，‌`ZipInputStream`的大小不会比整个ZIP文件大，‌因为它只是ZIP文件内容的流式传输方式。‌使用`ZipInputStream`读取ZIP文件时，‌数据是从ZIP文件中逐个字节读取的，‌而不是将整个ZIP文件的内容一次性加载到内存中。‌这意味着，‌从理论上讲，‌`ZipInputStream`的大小始终与ZIP文件的大小保持一致，‌或者更准确地说是与当前正在读取的部分保持一致。‌因此，‌通过`ZipInputStream`读取的数据量不会超过ZIP文件本身的大小



##### java 上传文件到服务器是先把文件全部加载到内存么

在Java中，上传文件到服务器通常使用HTTP协议，这是通过网络进行的。文件不需要完全加载到内存中，而是以流的形式进行传输。这意味着文件可以分块传输，每次只读取一块数据发送到服务器。

### 3. 加解密订单敏感字段

通过 mybatis  的拦截器拦截  参数和结果返回，  配合注解，实现加解密、

### 3. 拆单合单

状态流转机器

### 4. 支付和退款

表：支付流水记录  退款流水记录   支付配置表   支付退款不成功回调表

支付逻辑

两个接口 

pay   交易中心调支付，进行预支付

getByid   获取预支付的前端渲染信息

payNotify 微信回调

```
支付流程：交易中心下单时请求网关向微信发送预支付  并且把回调地址告诉微信，如果成功，返回支付单ID给前端
	前端下单成功后，支付的时候通过支付凭证ID向支付中心请求 支付渲染的数据
	
客户支付完后，微信会调支付网关得notify接口；  返回json字符串，支付网关根据渠道解析； 如果支付记录状态(PENDING,FAIL,SUCCESS)==PENDING 幂等
则 回调交易中心返回支付成功，如果catch失败插入回调表，  不管怎样都返回微信成功的标识

回调表定时任务扫描失败的记录进行回调, 进行次数 + 每次延迟的情况

如果通知失败则采用回调表定时任务检查的方式;
```

退款逻辑

```
交易中心 -> 支付网关refund 接口  支付单号，退款单号-交易中心生成，退款金额，回调交易中心URL

refund接口 -> 校验所有的退款成功的单号，如果总退款金额>当前支付单号金额，则不给退款  
       -> 调微信预退款， 成功返回状态设置 PENDING状态，等待微信成功退款后回调

refundNotify 接口-> 微信退款回调， 此时也要回调交易中心，如果失败就加入流水记录表回调
```

